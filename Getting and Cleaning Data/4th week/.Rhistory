download.file(con2, paste(fileloc, "FEDSTATS_Country.csv"), mode='wb')
dataset1 <- read.csv(paste(fileloc, "FGDP.csv"))
dataset2 <- read.csv(paste(fileloc, "FEDSTATS_Country.csv"))
View(dataset1)
dataset1 <- read.csv(paste(fileloc, "FGDP.csv"), HEADER=F, skip=5)
dataset1 <- read.csv(paste(fileloc, "FGDP.csv"), header=F, skip=5)
View(dataset1)
?read.csv
dataset1 <- read.csv(paste(fileloc, "FGDP.csv"), header=F, skip=5, colnames=c("CountryCode", "CountryID", "Blank", "Economy", "USD"))
dataset1 <- read.csv(paste(fileloc, "FGDP.csv"), header=F, skip=5, colnames=c("CountryCode", "CountryID", "Blank", "Economy", "USD"))
View(dataset1)
dataset1 <- read.csv(paste(fileloc, "FGDP.csv"), header=F, skip=5, colnames=c("CountryCode", "CountryID", "Blank", "Economy", "USD", "v6", "v7", "v8", "v9", "v10"))
dataset1 <- read.csv(paste(fileloc, "FGDP.csv"), header=F, skip=5)
View(dataset1)
dataset1[,c("V1","V2","V3","V4","V5")]
dataset1 <- dataset1[,c("V1","V2","V3","V4","V5")]
?rename
dataset1 <- dataset1[,c("V1","V2","V4","V5")]
View(dataset1)
rename(dataset1, c("CCode","CID","Economy","USD"))
View(dataset1)
View(dataset1)
?fread
library(data.table)
dataset1 <- fread(paste(fileloc, "FGDP.csv"), header=F, skip=5)
?fread
dataset1 <- fread(paste(fileloc, "FGDP.csv"), header=F, skip=5, select(c(1,2,4,5)), col.names = c("CCode","CID","Economy","USD"))
dataset1 <- fread(paste(fileloc, "FGDP.csv"), header=F, skip=5, select = c(1,2,4,5), col.names = c("CCode","CID","Economy","USD"))
View(dataset1)
dataset2 <- fread(paste(fileloc, "FEDSTATS_Country.csv"))
View(dataset2)
?merge
dataset1 <- fread(paste(fileloc, "FGDP.csv"), header=F, skip=5, select = c(1,2,4,5), col.names = c("CountryCode","CID","Economy","USD"))
dataset2 <- fread(paste(fileloc, "FEDSTATS_Country.csv"))
dataset <- merge(dataset1, dataset2, by = "CountryCode")
nrows(dataset)
nrow(dataset)
View(dataset)
dataset <- merge(dataset2, dataset1, by = "CountryCode")
nrow(dataset)
View(dataset1)
dataset1 <- fread(paste(fileloc, "FGDP.csv"), header=F, skip=5, select = c(1,2,4,5), col.names = c("CountryCode","CID","Economy","USD"), nrow=190)
dataset2 <- fread(paste(fileloc, "FEDSTATS_Country.csv"))
dataset <- merge(dataset1, dataset2, by = "CountryCode")
nrow(dataset)
?order
View(dataset)
setorderv(dataset, cols = CID)
setorderv(dataset, cols = "CID", order=1)
x <- setorderv(dataset, cols = "CID", order=1)
View(x)
x <- setorderv(dataset, cols = "CID", order=-1)
View(x)
dataset <- setorderv(dataset, cols = "CID", order=-1)
dataset[13]
dataset$CountryCode[13]
dataset$Economy[13]
View(dataset)
table(dataset$`Income Group`)
View(dataset)
dataset[, lapply(mean), by = .(Income Group)]
dataset[, lapply(mean), by = .(Income group)]
dataset[, lapply(mean), by = "Income group"]
View(dataset)
dataset[, lapply(mean), by = "Income Group"]
dataset(sapply(mean))
View(dataset)
dataset[`Income Group` == "High income: OECD"
, lapply(mean)
, .SDcols = c("CID")
, by = "Income Group"]
dataset[`Income Group` == "High income: OECD"
, lapply(.mean)
, .SDcols = c("CID")
, by = "Income Group"]
dataset[`Income Group` == "High income: OECD"
, lapply(.SD, mean)
, .SDcols = c("CID")
, by = "Income Group"]
dataset[`Income Group` == "High income: nonOECD"
, lapply(.SD, mean)
, .SDcols = c("CID")
, by = "Income Group"]
breaks <- quantile(dataset[, Rank], probs = seq(0, 1, 0.2), na.rm = TRUE)
breaks <- quantile(dataset[, CID], probs = seq(0, 1, 0.2), na.rm = TRUE)
breaks
dataset$qGDP <- cut(dataset[, CID], breaks = breaks)
dataset[`Income Group` == "Lower middle income", .N, by = c("Income Group", "qGDP")]
swirl()
librry(swirl)
library(swirl)
swirl()
mydf <- read.csv(path2csv = F, stringsAsFactors = F)
mydf <- read.csv(path2csv, stringsAsFactors = F)
mydf <- read.csv(path2csv, stringsAsFactors = FALSE)
dim()
dim(mydf)
head(mydf)
library(dplyr)
packageVersion(dplyr)
packageVersion("dplyr")
cran <. tbl_df(mydf)
cran <- tbl_df(mydf)
rm(mydf)
rm("mydf")
cran
?select
View(cran)
select(cran, ipd_id, package, country)
select(cran, ip_id, package, country)
5:20
select(cran, r_arch:country)
select(cran, country:r_arch)
cran
select(cran, -time)
select(cran, -5:20)
select(cran, -5:20)
-5:20
(-5:20)
-(5:20)
select(cran, -(5:20))
select(cran, -(x:size))
select(cran, -(x:size))
info()
mxt()
nxt()
View(cran)
select(cran, -(X:size))
filter(cran, package =="swirl")
filter(cran, r_version == "3.1.1.", country = "US")
filter(cran, r_version == "3.1.1.", country == "US")
filter(cran, r_version == "3.1.1", country == "US")
?Comparison
filter(cran, r_version == "3.0.2", country == "IN")
filter(cran, r_version <= "3.0.2", country == "IN")
filter(cran, r_version <= "3.0.2", country == "IN")
filter(cran, country == "uS" | country == "IN")
filter(cran, country == "uS" | country == "IN")
filter(cran, country == "US" | country == "IN")
filter(cran, size > 100500, r_os == "linux-gnu")
is.na(3,5,NA, 10)
is.na(c(3,5,NA,10))
!is.na(c(3,5,NA,10))
filter(cran, r_version == !is.na())
filter(cran, !is.na(r_version))
cran2 <- selet(cran, size:ip_id)
cran2 <- select(cran, size:ip_id)
arrange(cran2, ip_id)
arrange(cran2, desc(ip_id))
arrange(cran2, package, ip_id)
arrange(cran2, country, desc(r_version), ip_id)
cran3 <- select(cran, ip_id, package, size)
cran3
mutate(cran3, size_mb = size/ 2^20)
mutate(cran3, size_mb = size/ 2^20, size_gb = size/ 2^10)
mutate(cran3, size_mb = size/ 2^20, size_gb = size_mb/ 2^10)
mutate(cran3, correct_size = size - 1000)
mutate(cran3, correct_size = size + 1000)
summarize(cran3, avg_bytes = mean(size))
summarize(cran3, avg_bytes = mean(size))
summarize(cran, avg_bytes = mean(size))
swirl()
library(swirl)
swirl()
library(dplyr)
cran <- tbl_df(mydf)
rm("mydf")
cran
?group_by
by_package <- group_by(cran)
by_package <- group_by(cran, package)
by_package
summarise(apply mean(size))
?
fdf
summarise(apply(mean(size)))
summarise(by_package, mean(size))
submit()
pack_sum <- summarize(by_package,
count = n(),
unique = n_distinct(ip_id),
countries = n_distinct(country),
avg_bytes = mean(size))
?n
?n_distinct
submit()
pack_sum <- summarize(by_package,
count = n(),
unique = n_distinct(ip_id),
countries = n_distinct(country),
avg_bytes = mean(size))
pack_sum
submit()
submit()
pack_sum
quantile(pack_sum$count, probs = 0.99)
top_counts
top_counts <- filter(pack_sum, count > 679)
top_counts
View(top_counts)
top_counts_sorted <- arrang(top_counts, desc(count))
top_counts_sorted <- arrange(top_counts, desc(count))
View(top_counts_sorted)
quantile(pack_sum$unique, probs = 0.99)
top_unique <- filter(pack_sum, unique > 465)
view(top_unique)
View(top_unique)
top_unique_sorted <- arrange(top_unique, desc(unique))
View(top_unique_sorted)
submit()
submit()
?chain
??chain
submit()
View(result3)
submit()
cran %>%
select(ip_id, country, package, size) %>%
mutate(size_mb <- size /2^20)
submit()
submit()
submit()
cran %>%
select(ip_id, country, package, size) %>%
mutate(size_mb = size / 2^20) %>%
# Your call to filter() goes here
filter(size_mb <= 0.5)
print()
cran %>%
select(ip_id, country, package, size) %>%
mutate(size_mb = size / 2^20) %>%
# Your call to filter() goes here
filter(size_mb <= 0.5)
print
submit()
cran %>%
select(ip_id, country, package, size) %>%
mutate(size_mb = size / 2^20) %>%
# Your call to filter() goes here
filter(size_mb <= 0.5) %>%
print
submit()
submit()
# arrange() the result by size_mb, in descending order.
#
# If you want your results printed to the console, add
# print to the end of your chain.
cran %>%
select(ip_id, country, package, size) %>%
mutate(size_mb = size / 2^20) %>%
filter(size_mb <= 0.5) %>%
# Your call to arrange() goes here
arrange(desc(size_mb)) %>%
print
submit()
0
library(swirl)
swirl()
Sys.getlocale()
Sys.getlocale("LC_TIME")
library(lubridale)
library(lubridate)
help(package = "lubridate")
help(package = lubridate)
today()
this_day <- today()
this_Day
this_day
year(this_day)
wday(this_day)
wday(this_day, label=T)
wday(this_day, label=TRUE)
row(this_day)
now(this_day)
this_moment <- now(this_day)
this_moment <- now()
this_moment
minute(this_moment)
my_date <- ymd("1989-05-17")
my_date
class(my_date)
ymd("1989 May 17")
ymd("MArch 12, 1975")
mdy("MArch 12, 1975")
mdy("March 12, 1975")
dmy(15081985)
dmy(25081985)
dmy("192012")
ymd("192012")
ymd("--192012")
ymd("1920/1/2")
dt1
ymd_hms(dt1)
hms("03:22:14")
dt2
ymd(dt2)
update(this_moment, hours = 8, minutes = 34, seconds = 55)
this_moment
update(this_moment, now())
update(this_moment, hourse = 1, minutes = 15)
update(this_moment, hourse = 10, minutes = 16)
update(this_moment, hourse = 10, minutes = 16, seconds = 0)
update(this_moment, hours = 10, minutes = 16, seconds = 0)
this_moment <- update(this_moment, hours = 10, minutes = 16, seconds = 0)
this_moment
nyc <- now("America/New_york")
nyc <- now("America/New_York")
nyc
depart <- nyc + days(2)
depart
depart <- update(depart, hours = 17, minutes = 34, seconds = 0)
depart <- update(depart, hours = 17, minutes = 34)
depart
arrive <- depart + hours(15) + minutes(50)
?with_tz()
?with_tz()
?with_tz
arrive <- with_tz(tzone="Asia/Hong_Kong")
arrive <- with_tz(arrive, tzone="Asia/Hong_Kong")
arrive
last_time <- mdy(June 17, 2008, tz = "Singapore")
last_time <- mdy("June 17, 2008", tz = "Singapore")
last_time
?interval()
?interval
how_long <. last_time %--% arrive
how_long <- last_time %--% arrive
how_long <- interval(last_time, arrive)
as.period(how_long)
stopwatch()
install_course("Exploratory Data Analysis")
swirl()
library(swirl)
swirl()
getwd()
setwd('./Development/R/datasciencecoursera/Getting and Cleaning Data/4th week/')
con = 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv'
con = 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv'
download.file(con)
download.file(con, "/")
download.file(con, ".")
download.file(con, "")
download.file(con, getwd())
setwd('./Development/R/datasciencecoursera/Getting and Cleaning Data/4th week/')
con = 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv'
download.file(con, getwd())
download.file(con, "dataset.csv")
if (file.exists("dataset.csv")) file.remove("dataset.csv")
df <- read.csv("dataset.csv")
download.file(con, "dataset.csv")
con = 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv'
download.file(con, "dataset.csv")
df <- read.csv("dataset.csv")
if (file.exists("dataset.csv")) file.remove("dataset.csv")
View(df)
apply(strsplit(colnames(df$wgtp)))
?strsplit
apply(strsplit(colnames(df$wgtp)), "wgtp")
apply(strsplit(df$wgtp), "wgtp")
tapply(strsplit(df$wgtp), "wgtp")
?apply
apply(df$wgtp, strsplit("wgtp"))
apply(df$wgtp, 2, strsplit("wgtp"))
?apply
apply(df$wgtp, 1, strsplit("wgtp"))
?strsplit
apply(df$wgtp, 1, strsplit(df$wgtp, "wgtp"))
apply(df$wgtp, 1, strsplit(df$wgtp, c("wgtp")))
varNames <- names(df)
varNamesSplit <- strsplit(varNames, "wgtp")
varNamesSplit[[123]]
varNamesSplit <- strsplit(colnames(df), "wgtp")
varNamesSplit[[123]]
con = 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv'
download.file(con, "dataset.csv")
df <- read.csv("dataset.csv")
if (file.exists("dataset.csv")) file.remove("dataset.csv")
View(df)
download.file(con, "dataset.csv")
df <- read.csv("dataset.csv", skip = 4, nrows = 215, stringsAsFactors = FALSE)
if (file.exists("dataset.csv")) file.remove("dataset.csv")
View(df)
df <- df[, c("X", "X.1", "X.2", "X.3")]
View(df)
download.file(con, "dataset.csv")
df <- read.csv("dataset.csv", skip = 4, nrows = 215, stringsAsFactors = FALSE)
if (file.exists("dataset.csv")) file.remove("dataset.csv")
df <- df[, c("X", "X.1", "X.3", "X.4")]
View(df)
df <- df[X != ""]
df <- df["X" != ""]
View(df)
View(df)
?gsub
?mean
mean(gsub(",", "", df$X.4))
class(df)
class(df$X.4)
mean(as.numeric(gsub(",", "", df$X.4)))
x <- mean(as.numeric(gsub(",", "", df$X.4)))
x
x <- mean(as.numeric(gsub(",", "", df$X.4)), na.rm=T)
x
mean(as.numeric(gsub(",", "", df$X.4)), na.rm=T)
grep("^United",countryNames), 4
View(df)
rename(df, c("X"="countryNames"))
library(dplyr)
rename(df, c("X"="countryNames"))
colnames(df)[colnames(df$X)] <- "countryNames"
View(df)
df <- colnames(df)[colnames(df$X)] <- "countryNames"
con = 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv'
con = 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv'
download.file(con, "dataset.csv")
df <- read.csv("dataset.csv", skip = 4, nrows = 215, stringsAsFactors = FALSE)
if (file.exists("dataset.csv")) file.remove("dataset.csv")
df <- df["X" != ""]
df <- df[, c("X", "X.1", "X.3", "X.4")]
x <- mean(as.numeric(gsub(",", "", df$X.4)), na.rm=T)
x
colnames(df)[colnames(df$X)] <- "countryNames"
View(df)
colnameS(df$X) <- "countryNames"
colnameS[df$X] <- "countryNames"
colnameS[df$X]
colnames[df$X] <- "countryNames"
colnames[df$X]
colnames(df)
colnames(df)[1]
colnames(df)[1] <- "countryNames"
View(df)
grep("^United",countryNames), 4
grep("^United",countryNames)
grep("^United",df$countryNames)
howmuch1 <- grepl("^United",df$countryNames)
summary(howmuch1)
con = 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv'
download.file(con, "dataset.csv")
df <- read.csv("dataset.csv")
View(df)
df <- read.csv("dataset.csv", skip = 4, nrows = 215, stringsAsFactors = FALSE)
View(df)
df <- read.csv("dataset.csv", skip = 4, nrows = 191, stringsAsFactors = FALSE)
View(df)
df <- read.csv("dataset.csv", skip = 4, nrows = 190, stringsAsFactors = FALSE)
con = 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv'
con = 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv'
download.file(con, "dataset1.csv")
df <- read.csv("dataset1.csv")
View(df)
View(df)
con = 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv'
download.file(con, "dataset1.csv")
df1 <- read.csv("dataset.csv", skip = 4, nrows = 190, stringsAsFactors = FALSE)
con = 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv'
download.file(con, "dataset2.csv")
df2 <- read.csv("dataset1.csv")
if (file.exists("dataset1.csv")) file.remove("dataset1.csv")
if (file.exists("dataset2.csv")) file.remove("dataset2.csv")
View(df1)
?mergeÄ‘
?merge
View(df1)
View(df2)
View(df1)
View(df2)
View(df)
con = 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv'
download.file(con, "dataset1.csv")
df1 <- read.csv("dataset.csv", skip = 4, nrows = 190, stringsAsFactors = FALSE)
View(df1)
View(df1)
df1 <- df1[, c("X", "X.1", "X.3", "X.4")]
colnames(df1)[1] <- "countryNames"
con = 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv'
download.file(con, "dataset2.csv")
df2 <- read.csv("dataset1.csv")
View(df2)
con = 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv'
download.file(con, "dataset2.csv")
df2 <- read.csv("dataset2.csv")
View(df2)
colnames(df1)[1] <- "CountryCode"
if (file.exists("dataset1.csv")) file.remove("dataset1.csv")
if (file.exists("dataset2.csv")) file.remove("dataset2.csv")
df <- merge(df1, df2, by="CountryCode")
View(df)
isFiscalYearEnd <- grepl("fiscal year end", tolower(df$Special.Notes))
isJune <- grepl("june", tolower(dt$Special.Notes))
isJune <- grepl("june", tolower(df$Special.Notes))
table(isFiscalYearEnd, isJune)
library(quantmod)
amzn = getSymbols("AMZN",auto.assign=FALSE)
install.packages("quantmod")
library(quantmod)
amzn = getSymbols("AMZN",auto.assign=FALSE)
sampleTimes = index(amzn)
year(sampleTimes)
table(year(sampleTimes))
table(day(sampleTimes))
table(day(sampleTimes), label = TRUE)
d(sampleTimes), label = TRUE
sampleTimes
day(ymd(sampleTimes), label = TRUE)
day(ymd(sampleTimes), label = TRUE, abbr=FALSE)
ymd(sampleTimes)
day(ymd(sampleTimes))
wday(ymd(sampleTimes), label=TRUE)
table(wday(ymd(sampleTimes), label=TRUE))
?wday
table(year(sampleTimes), weekdays(sampleTimes))
